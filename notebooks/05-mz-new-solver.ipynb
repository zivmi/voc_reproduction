{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating functions VoC for fitting ridge regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgesvd(Y, X, lambd):\n",
    "    \"\"\"\n",
    "    Computes ridge regression coefficients using singular value decomposition.\n",
    "    \n",
    "    Parameters:\n",
    "        Y : array_like\n",
    "            Target vector of shape (T,).\n",
    "        X : array_like\n",
    "            Design matrix of shape (T, P).\n",
    "        lambd : array_like\n",
    "            Array of ridge regularization parameters of shape (L,).\n",
    "    \n",
    "    Returns:\n",
    "        B : ndarray\n",
    "            Ridge regression coefficients of shape (P, L).\n",
    "    \"\"\"\n",
    "    if np.isnan(X).sum() + np.isnan(Y).sum() > 0:\n",
    "        raise ValueError(\"Missing data\")\n",
    "\n",
    "    L = len(lambd)\n",
    "    # MATLAB uses 'gesvd', default is 'gesdd'\n",
    "    U, d, Vt = svd(X, check_finite=False, lapack_driver='gesvd') \n",
    "    T, P = X.shape\n",
    "\n",
    "    if T >= P:\n",
    "        compl = np.zeros((P, T - P))\n",
    "    else:\n",
    "        compl = np.zeros((P - T, T))\n",
    "    \n",
    "    B = np.zeros((P, L))\n",
    "\n",
    "    for l in range(L):\n",
    "        if T >= P:\n",
    "            B[:, l] = Vt.T @ np.hstack((np.diag(d / (d**2 + lambd[l])), compl)) @ U.T @ Y\n",
    "        else:\n",
    "            B[:, l] = Vt.T @ np.vstack((np.diag(d / (d**2 + lambd[l])), compl)) @ U.T @ Y\n",
    "    \n",
    "    return B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(Y, X, lambda_list):\n",
    "    \"\"\"\n",
    "    Computes beta coefficients using ridge regression with SVD.\n",
    "    \n",
    "    Parameters:\n",
    "        Y : array_like\n",
    "            Target vector of shape (T,).\n",
    "        X : array_like\n",
    "            Features matrix of shape (T, P).\n",
    "        lambda_list : array_like\n",
    "            Array of ridge regularization parameters of shape (L,).\n",
    "    \n",
    "    Returns:\n",
    "        B : ndarray\n",
    "            Ridge regression coefficients of shape (P, L).\n",
    "    \"\"\"\n",
    "    if np.isnan(X).sum() + np.isnan(Y).sum() > 0:\n",
    "        raise ValueError(\"Missing data\")\n",
    "    \n",
    "    L_ = len(lambda_list)\n",
    "    T_ = X.shape[0]\n",
    "    P_ = X.shape[1]\n",
    "\n",
    "    if P_ > T_:\n",
    "        a_matrix = X @ X.T / T_  # T_ x T_\n",
    "    else:\n",
    "        a_matrix = X.T @ X / T_  # P_ x P_\n",
    "\n",
    "    U_a, d_a, _ = svd(a_matrix, check_finite=False, lapack_driver='gesvd')\n",
    "    scale_eigval = ((d_a * T_)**(-1/2))\n",
    "\n",
    "    # originally only the X.T version was implemented, but that\n",
    "    # causes error in multiplication of matrices even in the original\n",
    "    # MATLAB code. The second brach (P<=T) is not used because in that\n",
    "    # regime 'ridgesvd' is used, not 'get_beta'.\n",
    "    if P_ > T_:\n",
    "        W = X.T @ U_a @ np.diag(scale_eigval)\n",
    "    else:\n",
    "        W = X @ U_a @ np.diag(scale_eigval)\n",
    "\n",
    "    a_matrix_eigval = d_a #.reshape(-1, 1)  # P_ x 1\n",
    "    \n",
    "    # FIXME the following code does not run for P<=T\n",
    "    # Fix it so that it runs. \n",
    "    signal_times_return = X.T @ Y / T_  # (SR): M x 1\n",
    "    signal_times_return_times_v = W.T @ signal_times_return  # V' * (SR): T_ x 1\n",
    "\n",
    "    B = np.zeros((P_, L_))\n",
    "    for l in range(L_):\n",
    "        B[:, l] = W @ np.diag(1 / (a_matrix_eigval + lambda_list[l])) @ signal_times_return_times_v\n",
    "\n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951307904983197\n",
      "0.0\n",
      "1.6281699838187336e-11\n",
      "2.7122509967114627e-14\n",
      "2.2494674309023188e-14\n",
      "2.2494674309023188e-14\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "T = 100\n",
    "P = 1000\n",
    "X = np.random.randn(T, P)\n",
    "Y = np.random.randn(T)\n",
    "lambd = np.array([1])\n",
    "\n",
    "B_ridgesvd = ridgesvd(Y, X, lambd).flatten()\n",
    "B_get_beta = get_beta(Y, X, lambd).flatten()\n",
    "B_sklearn = np.linalg.inv(X.T @ X + lambd[0] * np.eye(P)) @ X.T @ Y\n",
    "B_sklearn_svd = Ridge(alpha=lambd[0], fit_intercept=False, solver=\"svd\").fit(X, Y).coef_\n",
    "B_sklearn_auto = Ridge(alpha=lambd[0], fit_intercept=False, solver=\"auto\").fit(X, Y).coef_\n",
    "B_sklearn_cholesky = Ridge(alpha=lambd[0], fit_intercept=False, solver=\"cholesky\").fit(X, Y).coef_\n",
    "\n",
    "\n",
    "ref = B_ridgesvd\n",
    "print(np.sum(abs(ref - B_get_beta)))\n",
    "print(np.sum(abs(ref - B_ridgesvd)))\n",
    "print(np.sum(abs(ref - B_sklearn)))\n",
    "print(np.sum(abs(ref - B_sklearn_svd)))\n",
    "print(np.sum(abs(ref - B_sklearn_auto)))\n",
    "print(np.sum(abs(ref - B_sklearn_cholesky)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.6 ms ± 4.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "18.5 ms ± 3.53 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "119 ms ± 4.71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "30.7 ms ± 3.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.87 ms ± 118 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "1.85 ms ± 134 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ridgesvd(Y, X, lambd).flatten()\n",
    "%timeit get_beta(Y, X, lambd).flatten()\n",
    "%timeit np.linalg.inv(X.T @ X + lambd[0] * np.eye(P)) @ X.T @ Y\n",
    "%timeit Ridge(alpha=lambd[0], fit_intercept=False, solver=\"svd\").fit(X, Y).coef_\n",
    "%timeit Ridge(alpha=lambd[0], fit_intercept=False, solver=\"auto\").fit(X, Y).coef_\n",
    "%timeit Ridge(alpha=lambd[0], fit_intercept=False, solver=\"cholesky\").fit(X, Y).coef_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
